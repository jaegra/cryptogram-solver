{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from string import ascii_lowercase as LETTERS\n",
    "from random import sample, choice, uniform\n",
    "from time import time\n",
    "from math import log, exp\n",
    "import codecs\n",
    "import csv\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cryptogram_solver import data\n",
    "from cryptogram_solver import solver\n",
    "from cryptogram_solver import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path.cwd().parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/chris/Documents/cryptogram-solver/notebooks')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data.get_news_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=20180827)\n",
    "# news_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=20180827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Token(ngrams=('<',), kind='char', n=1): 4,\n",
       " Token(ngrams=('<', 'a'), kind='char', n=2): 1,\n",
       " Token(ngrams=('<', 'a', '>'), kind='char', n=3): 1,\n",
       " Token(ngrams=('<', 'i'), kind='char', n=2): 1,\n",
       " Token(ngrams=('<', 'i', 's'), kind='char', n=3): 1,\n",
       " Token(ngrams=('<', 's'), kind='char', n=2): 1,\n",
       " Token(ngrams=('<', 's', 'e'), kind='char', n=3): 1,\n",
       " Token(ngrams=('<', 't'), kind='char', n=2): 1,\n",
       " Token(ngrams=('<', 't', 'h'), kind='char', n=3): 1,\n",
       " Token(ngrams=('>',), kind='char', n=1): 4,\n",
       " Token(ngrams=('a',), kind='char', n=1): 1,\n",
       " Token(ngrams=('a',), kind='word', n=1): 1,\n",
       " Token(ngrams=('a', '>'), kind='char', n=2): 1,\n",
       " Token(ngrams=('c',), kind='char', n=1): 1,\n",
       " Token(ngrams=('c', 'e'), kind='char', n=2): 1,\n",
       " Token(ngrams=('c', 'e', '>'), kind='char', n=3): 1,\n",
       " Token(ngrams=('e',), kind='char', n=1): 3,\n",
       " Token(ngrams=('e', '>'), kind='char', n=2): 1,\n",
       " Token(ngrams=('e', 'n'), kind='char', n=2): 2,\n",
       " Token(ngrams=('e', 'n', 'c'), kind='char', n=3): 1,\n",
       " Token(ngrams=('e', 'n', 't'), kind='char', n=3): 1,\n",
       " Token(ngrams=('h',), kind='char', n=1): 1,\n",
       " Token(ngrams=('h', 'i'), kind='char', n=2): 1,\n",
       " Token(ngrams=('h', 'i', 's'), kind='char', n=3): 1,\n",
       " Token(ngrams=('i',), kind='char', n=1): 2,\n",
       " Token(ngrams=('i', 's'), kind='char', n=2): 2,\n",
       " Token(ngrams=('i', 's', '>'), kind='char', n=3): 2,\n",
       " Token(ngrams=('is',), kind='word', n=1): 1,\n",
       " Token(ngrams=('n',), kind='char', n=1): 2,\n",
       " Token(ngrams=('n', 'c'), kind='char', n=2): 1,\n",
       " Token(ngrams=('n', 'c', 'e'), kind='char', n=3): 1,\n",
       " Token(ngrams=('n', 't'), kind='char', n=2): 1,\n",
       " Token(ngrams=('n', 't', 'e'), kind='char', n=3): 1,\n",
       " Token(ngrams=('s',), kind='char', n=1): 3,\n",
       " Token(ngrams=('s', '>'), kind='char', n=2): 2,\n",
       " Token(ngrams=('s', 'e'), kind='char', n=2): 1,\n",
       " Token(ngrams=('s', 'e', 'n'), kind='char', n=3): 1,\n",
       " Token(ngrams=('sentence',), kind='word', n=1): 1,\n",
       " Token(ngrams=('t',), kind='char', n=1): 2,\n",
       " Token(ngrams=('t', 'e'), kind='char', n=2): 1,\n",
       " Token(ngrams=('t', 'e', 'n'), kind='char', n=3): 1,\n",
       " Token(ngrams=('t', 'h'), kind='char', n=2): 1,\n",
       " Token(ngrams=('t', 'h', 'i'), kind='char', n=3): 1,\n",
       " Token(ngrams=('this',), kind='word', n=1): 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_test = solver.Tokenizer()\n",
    "tokenizer_test.tokenize(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:18<00:00, 38.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109402\n",
      "{('word', 1): 10030400, ('char', 1): 67208536, ('char', 2): 57178136, ('char', 3): 47147736}\n"
     ]
    }
   ],
   "source": [
    "reload(solver)\n",
    "tokenizer = solver.Tokenizer(char_ngram_range=(1, 3), word_ngram_range=(1, 1), vocab_size=1000000)\n",
    "tokenizer.fit(docs[:10000])\n",
    "print(len(tokenizer.vocab))\n",
    "print(tokenizer.totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('char', 1): 67208536,\n",
       " ('char', 2): 57178136,\n",
       " ('char', 3): 47147736,\n",
       " ('word', 1): 10030400}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ecrdiunlbu  —   kbunpsrribuco pstwaoikcur dchs c use fscp edsu il kbxsr lb ldsip    dscold kcps ocerwil cnciurl lds bacxc cyxiuirlpclibu: ldsm xindl eiu. lds iukbxiun lpwxt cyxiuirlpclibu kbwoy kdbbrs lb ub obunsp ysfsuy lds sqskwlihs apcukd cnciurl lds rwil, edikd kdcoosunsr lds cyxiuirlpclibu’r cwldbpilm lb rtsuy aiooibur bf yboocpr bu dscold iurwpcuks rwariyisr fbp   cuy   cxspikcur, dcuyiun dbwrs pstwaoikcur c ain hiklbpm bu    irrwsr. awl c rwyysu obrr bf lds yirtwlsy rwariyisr kbwoy kbuksihcaom kcwrs lds dscold kcps tpbnpcx lb ixtobys, oschiun xiooibur bf tsbtos eildbwl ckksrr lb dscold iurwpcuks asfbps pstwaoikcur dchs tpstcpsy c pstocksxsul. ldcl kbwoy oscy lb kdcbr iu lds iurwpcuks xcpgsl cuy rtwp c tboilikco ackgocrd vwrl cr pstwaoikcur nciu fwoo kbulpbo bf lds nbhspuxsul. lb rlchs bff ldcl bwlkbxs, pstwaoikcur kbwoy fiuy ldsxrsohsr iu lds cegecpy tbrilibu bf cttpbtpicliun dwns rwxr lb lsxtbpcpiom tpbt wt lds bacxc dscold kcps oce, cunspiun kbursphclihs hblspr edb dchs assu ysxcuyiun cu suy lb lds oce fbp mscpr. iu cubldsp leirl, ybucoy v. lpwxt’r cyxiuirlpclibu, ebppisy cabwl tpsrsphiun sqskwlihs apcukd tpspbnclihsr, kbwoy kdbbrs lb findl ilr pstwaoikcu cooisr iu lds dbwrs bu rbxs ksulpco jwsrlibur iu lds yirtwls. scnsp lb chbiy cu wnom tboilikco tioswt, pstwaoikcur bu kctilbo dioo cuy lds lpwxt lpcurilibu lscx cps ncxiun bwl dbe lb dcuyos lds ocerwil, edikd, cflsp lds sosklibu, dcr assu twl iu oixab wulio cl oscrl ocls fsapwcpm am lds wuilsy rlclsr kbwpl bf cttscor fbp lds yirlpikl bf kbowxaic kipkwil. ldsm cps ubl msl pscym lb yihwons ldsip rlpclsnm. “nihsu ldcl ldir tsuyiun oilinclibu iuhbohsr lds bacxc cyxiuirlpclibu cuy kbunpsrr, il ebwoy as iucttpbtpicls lb kbxxsul,” rciy tdiooit v. aocuyb, c rtbgsrxcu fbp lds lpwxt lpcurilibu sffbpl. “wtbu lcgiun bffiks, lds lpwxt cyxiuirlpclibu eioo shcowcls ldir kcrs cuy coo psoclsy crtsklr bf lds cffbpycaos kcps ckl. ” iu c tblsulicoom   yskiribu iu 2015, vwyns pbrsxcpm x. kboomsp pwosy ldcl dbwrs pstwaoikcur dcy lds rlcuyiun lb rws lds sqskwlihs apcukd bhsp c rtsuyiun yirtwls cuy ldcl lds bacxc cyxiuirlpclibu dcy assu yirlpiawliun lds dscold iurwpcuks rwariyisr, iu hiboclibu bf lds kburlilwlibu, eildbwl cttpbhco fpbx kbunpsrr. lds vwrliks ystcplxsul, kbufiysul ldcl vwyns kboomsp’r yskiribu ebwoy as pshsprsy, jwikgom cttscosy, cuy lds rwariyisr dchs psxciusy iu tocks ywpiun lds cttsco. iu rwkksrrfwoom rssgiun c lsxtbpcpm dcol iu lds tpbkssyiunr cflsp xp. lpwxt ebu, dbwrs pstwaoikcur ocrl xbuld lboy lds kbwpl ldcl ldsm “cuy lds  ’r lpcurilibu lscx kwppsulom cps yirkwrriun tblsulico btlibur fbp psrbowlibu bf ldir xcllsp, lb lcgs sffskl cflsp lds  ’r iucwnwpclibu bu vcu. 20, 2017. ” lds rwrtsuribu bf lds kcrs, dbwrs ocemspr rciy, eioo “tpbhiys lds   cuy dir fwlwps cyxiuirlpclibu lixs lb kburiysp edsldsp lb kbuliuws tpbrskwliun bp lb bldspeirs psrbohs ldir cttsco. ” pstwaoikcu oscysprdit bffikicor iu lds dbwrs ckgubeosyns lds tbrriaioilm bf “kcrkcyiun sffsklr” if lds   tcmxsulr, edikd dchs lblcosy cu srlixclsy $13 aiooibu, cps rwyysuom rlbttsy. iurwpspr ldcl psksihs lds rwariyisr iu sqkdcuns fbp tcmiun    kbrlr rwkd cr ysywkliaosr cuy   fbp soiniaos kburwxspr kbwoy pcks lb ypbt kbhspcns riuks ldsm ebwoy as obriun xbusm. bhsp coo, lds obrr bf lds rwariyisr kbwoy ysrlcaioizs lds sulips tpbnpcx cuy kcwrs c ockg bf kbufiysuks ldcl oscyr bldsp iurwpspr lb rssg c jwikg sqil cr esoo. culikitcliun ldcl lds lpwxt cyxiuirlpclibu xindl ubl as iukoiusy lb xbwul c hinbpbwr findl cnciurl lds dbwrs pstwaoikcur nihsu lds  ’r yix hise bf lds dscold kcps oce, c lscx bf ocemspr ldir xbuld rbwndl lb iulsphsus iu lds kcrs bu asdcof bf leb tcplikitculr iu lds dscold kcps tpbnpcx. iu ldsip psjwsrl, lds ocemspr tpsyiklsy ldcl c ysco aslessu dbwrs pstwaoikcur cuy lds use cyxiuirlpclibu lb yirxirr bp rsllos lds kcrs “eioo tpbywks yshcrlcliun kbursjwsuksr fbp lds iuyihiywcor edb psksihs ldsrs psywklibur, cr esoo cr fbp lds uclibu’r dscold iurwpcuks cuy dscold kcps rmrlsxr nsuspcoom. ” ub xcllsp edcl dcttsur, dbwrs pstwaoikcur rcm, ldsm ecul lb tpshcio bu leb bhspcpkdiun kbukstlr: lds kbunpsrribuco tbesp bf lds twprs, cuy lds pindl bf kbunpsrr lb rws lds sqskwlihs apcukd if il hiboclsr lds kburlilwlibu psncpyiun ldcl rtsuyiun tbesp. dbwrs pstwaoikcur kbulsuy ldcl kbunpsrr ushsp cttpbtpiclsy lds xbusm fbp lds rwariyisr, cr psjwipsy am lds kburlilwlibu. iu lds rwil, edikd ecr iuilicoom kdcxtibusy am vbdu c. absdusp, lds dbwrs rtscgsp cl lds lixs, cuy oclsp iu dbwrs kbxxillss pstbplr, pstwaoikcur crrsplsy ldcl lds cyxiuirlpclibu, ysrtspcls fbp lds fwuyiun, dcy psjwipsy lds lpscrwpm ystcplxsul lb tpbhiys il ysrtils eiysrtpscy iulspuco rgstlikirx ldcl lds rtsuyiun ecr tpbtsp. lds edils dbwrs rciy ldcl lds rtsuyiun ecr c tspxcusul tcpl bf lds oce tcrrsy iu 2010, cuy ldcl ub cuuwco cttpbtpiclibu ecr psjwipsy  —   shsu ldbwnd lds cyxiuirlpclibu iuilicoom rbwndl bus. vwrl cr ixtbplcul lb dbwrs pstwaoikcur, vwyns kboomsp fbwuy ldcl kbunpsrr dcy lds rlcuyiun lb rws lds edils dbwrs bu ldir irrws  —   c pwoiun ldcl xcum osnco sqtsplr rciy ecr focesy  —   cuy ldsm ecul ldcl tpsksysul lb as rsl lb psrlbps kbunpsrribuco oshspcns bhsp lds sqskwlihs apcukd. awl bu rtsuyiun tbesp cuy rlcuyiun, lds lpwxt cyxiuirlpclibu xcm kbxs wuysp tpsrrwps fpbx cyhbkclsr bf tpsriysulico cwldbpilm lb findl lds dbwrs ub xcllsp ldsip rdcpsy hiser bu dscold kcps, riuks ldbrs tpsksysulr kbwoy dchs apbcy pstspkwrribur. il ir c kbxtoikclsy rsl bf ymucxikr ioowrlpcliun dbe c jwikg osnco hiklbpm fbp lds dbwrs iu lds lpwxt spc xindl kbxs eild kbrlr ldcl pstwaoikcur ushsp culikitclsy edsu ldsm lbbg bu lds bacxc edils dbwrs.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc = cg.Doc(news_test['data'][0].lower())\n",
    "doc = solver.Doc(docs[0].lower())\n",
    "mapper = solver.Mapping()\n",
    "mapper.scramble()\n",
    "doc = mapper.translate(doc)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1\n",
      "3.49\n",
      "0.607\n",
      "0.105\n",
      "0.0183\n"
     ]
    }
   ],
   "source": [
    "[print(f'{x:0.3g}') for x in np.exp(np.linspace(3, -4, 5))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Ideas:\n",
    "# > Implement simulated annealing properly (single swap and decision), with a reasonable temp scheduler.\n",
    "#   - This works! But need to play with temperature scheduler since results are sensitive to even small changes.\n",
    "# > Implement simulated annealing but using softmax and subsetting swap options.\n",
    "# > More swaps in the beginning, fewer later.\n",
    "# '''\n",
    "\n",
    "# def simulated_annealing(text, solver, tokenizer, num_epochs=10000, is_debug=True):\n",
    "#     logger = logging.getLogger(__name__)\n",
    "#     best_mapping = mapping = cg.Mapping()\n",
    "#     doc = cg.Doc(text)\n",
    "#     best_score = solver.score(doc)\n",
    "#     epoch = 0\n",
    "#     decisions = defaultdict(int)\n",
    "#     temps = np.exp(np.linspace(0, -6, num_epochs))\n",
    "#     decisions['good'], decisions['bad_keep'], decisions['bad_pass'] = 0, 0, 0\n",
    "#     for temp in tqdm(temps):\n",
    "#         improving = False\n",
    "#         new_mapping = mapping.random_swap(doc.letters)\n",
    "#         new_doc = new_mapping.translate(doc)\n",
    "#         score = solver.score(new_doc)\n",
    "#         score_change = score - best_score\n",
    "#         if score_change < 0:\n",
    "#             # logger.debug('updating (improvement)')\n",
    "#             best_mapping = new_mapping\n",
    "#             best_score = score\n",
    "#             decisions['good'] += 1\n",
    "#         elif exp(-score_change / temp) > uniform(0, 1):\n",
    "#             # Break this out as different section just for debugging.\n",
    "#             # logger.debug(f'updating (bad change): {score_change}')\n",
    "#             best_mapping = new_mapping\n",
    "#             best_score = score\n",
    "#             decisions['bad_keep'] += 1\n",
    "#         else:\n",
    "#             decisions['bad_pass'] += 1\n",
    "#             # logger.debug(f'keeping: {score_change}')\n",
    "#         mapping = best_mapping\n",
    "#         epoch += 1\n",
    "#         if epoch % 1000 == 0:\n",
    "#             logger.debug(f'{score:0.5g}, {mapping.mapping}, {mapping.translate(doc).text}')\n",
    "#             logger.debug(sorted(list(decisions.items())))\n",
    "#             logger.debug(pd.DataFrame(sorted(list(decisions.items()))))\n",
    "#             decisions = defaultdict(int)\n",
    "#     logger.info(f'\\nfinal best ({epoch} epochs): {best_score:0.5g}')\n",
    "#     return mapping.translate(doc).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 4, 4, 3, 3, 2, 2, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.round(np.linspace(5, 1, 10)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ideas:\n",
    "> Implement simulated annealing properly (single swap and decision), with a reasonable temp scheduler.\n",
    "  - This works! But need to play with temperature scheduler since results are sensitive to even small changes.\n",
    "> Implement simulated annealing but using softmax and subsetting swap options.\n",
    "> More swaps in the beginning, fewer later.\n",
    "'''\n",
    "\n",
    "def simulated_annealing(text, _, tokenizer, num_epochs=10000, is_debug=True):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    best_mapping = mapping = solver.Mapping()\n",
    "    doc = solver.Doc(text)\n",
    "    best_score = solver.score(doc)\n",
    "    epoch = 0\n",
    "    decisions = defaultdict(int)\n",
    "    temps = np.exp(np.linspace(0, -6, num_epochs))\n",
    "    n_swap_list = np.round(np.linspace(3, 1, num_epochs)).astype(int)\n",
    "    decisions['good'], decisions['bad_keep'], decisions['bad_pass'] = 0, 0, 0\n",
    "    for temp, n_swaps in tqdm(zip(temps, n_swap_list)):\n",
    "        improving = False\n",
    "        new_mapping = mapping.random_swap(n_swaps)\n",
    "        new_doc = new_mapping.translate(doc)\n",
    "        score = solver.score(new_doc)\n",
    "        score_change = score - best_score\n",
    "        if score_change < 0:\n",
    "            # logger.debug('updating (improvement)')\n",
    "            best_mapping = new_mapping\n",
    "            best_score = score\n",
    "            decisions['good'] += 1\n",
    "        elif exp(-score_change / temp) > uniform(0, 1):\n",
    "            # Break this out as different section just for debugging.\n",
    "            # logger.debug(f'updating (bad change): {score_change}')\n",
    "            best_mapping = new_mapping\n",
    "            best_score = score\n",
    "            decisions['bad_keep'] += 1\n",
    "        else:\n",
    "            decisions['bad_pass'] += 1\n",
    "            # logger.debug(f'keeping: {score_change}')\n",
    "        mapping = best_mapping\n",
    "        epoch += 1\n",
    "        if epoch % 1000 == 0:\n",
    "            logger.debug(f'{score:0.5g}, {mapping.key}, {mapping.translate(doc).text}')\n",
    "            # logger.debug(sorted(list(decisions.items())))\n",
    "            logger.debug(pd.DataFrame(sorted(list(decisions.items()))))\n",
    "            decisions = defaultdict(int)\n",
    "    logger.info(f'\\nfinal best ({epoch} epochs): {best_score:0.5g}')\n",
    "    return mapping.translate(doc).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = cg.Doc(doc.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(f'{x:0.3g}') for x in np.exp(np.linspace(-30, -5, 100))];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is slower than the code above, and less consistent. But it does work.\n",
    "\n",
    "# def choose_new_mapping(doc, mapping, score, proportion, temp):\n",
    "    \n",
    "#     swap_options = cg.get_swap_options(doc.letters, p=proportion)\n",
    "#     mapping_options = [mapping.swap(*s) for s in swap_options]\n",
    "#     scores = [solver.score(m.translate(doc)) for m in mapping_options]\n",
    "    \n",
    "#     # Add current without having to recompute score.\n",
    "#     mapping_options.append(mapping)\n",
    "#     scores.append(score)\n",
    "    \n",
    "#     probs = solver.softmax(-np.array(scores), temp)\n",
    "#     # print(max(probs))\n",
    "#     index = np.random.choice(range(len(probs)), size=1, p=probs)[0]\n",
    "    \n",
    "#     return mapping_options[index], scores[index]\n",
    "\n",
    "\n",
    "# def simulated_annealing(text, solver, tokenizer, epochs, epochsbug=True):\n",
    "#     logger = logging.getLogger(__name__)\n",
    "#     best_mapping = mapping = cg.Mapping()\n",
    "#     doc = cg.Doc(text)\n",
    "#     epoch = 0\n",
    "#     score = solver.score(mapping.translate(doc))\n",
    "#     temps = np.exp(np.linspace(0, -6, epochs))\n",
    "#     proportions = np.exp(np.linspace(-30, -5, epochs))\n",
    "#     for temp, proportion in tqdm(zip(temps, proportions)):\n",
    "#         mapping, score = choose_new_mapping(doc, mapping, score, proportion, temp)\n",
    "#         epoch += 1\n",
    "#         if epoch % 250 == 0:\n",
    "#             logger.debug((\n",
    "#                 f'{score:0.5g}, {mapping.mapping}, {mapping.translate(doc).text} '\n",
    "#                 f'temp: {temp:0.5g}, proportion: {proportion:0.5g}'\n",
    "#             ))\n",
    "#     logger.info(f'\\nfinal best ({epoch} epochs): {epoch:0.5g}')\n",
    "#     return mapping.translate(doc).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 22:33:44 DEBUG    hi\n"
     ]
    }
   ],
   "source": [
    "reload(solver)\n",
    "\n",
    "log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=log_fmt)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.debug('hi')\n",
    "\n",
    "sim_annealer = solver.Solver(tokenizer, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "987it [00:01, 891.93it/s]2019-02-08 22:34:05 DEBUG    16.046, eizrosjlcmqhpukwvnbfdgtyxa, Tlbf bf wla fwedx et z vbdh. Wle idbau z dbqad zru udeprau wla pleha pedhu. Aru plbha fla heeoau fe fzu br mlewevdzmlf, I zsfehnwahx heqa lad plar fla fjbhaf.\n",
      "2019-02-08 22:34:05 DEBUG    [('bad_keep', 357), ('bad_pass', 312), ('good', 331)]\n",
      "1983it [00:02, 869.65it/s]2019-02-08 22:34:06 DEBUG    14.572, rnlahbipzxgtfyvcudokqwsjem, Tegw gw ley wlsan sm d kgac. Wes pagyr d agoya dbr rasvbyr ley vescy vsacr. Abr vegcy wey csstyr ws wdr gb heslskadhew, I dfwscqlycn csoy eya veyb wey wzgcyw.\n",
      "2019-02-08 22:34:06 DEBUG    [('bad_keep', 263), ('bad_pass', 471), ('good', 266)]\n",
      "2967it [00:03, 901.10it/s]2019-02-08 22:34:07 DEBUG    14.564, wvnueompscklthiqgrdjaxbfyz, Tnoi oi mne imfry fx u qorl. Wnf jroes u rober ucs srfaces mne anfle afrls. Acs anole ine lffkes if ius oc hnfmfqruhni, I uwifldmely lfbe ner anec ine igolei.\n",
      "2019-02-08 22:34:07 DEBUG    [('bad_keep', 173), ('bad_pass', 642), ('good', 185)]\n",
      "3971it [00:04, 921.53it/s]2019-02-08 22:34:08 DEBUG    13.018, swlaefjyiuqrmkotbhpngxczdv, Tria ia pre apolh of d uilc. Wro wliey d lizel dty ylobtey pre broce bolcy. Aty brice are cooney ao ady it sropouldsra, I dqaocjpech coze rel bret are amicea.\n",
      "2019-02-08 22:34:08 DEBUG    [('bad_keep', 119), ('bad_pass', 772), ('good', 109)]\n",
      "4967it [00:05, 925.45it/s]2019-02-08 22:34:09 DEBUG    14.576, avudegfhijptlnoyzrswcmkbxq, This is lhe slorp og a firm. Who uried a riber and drotned lhe thome tormd. And thime she moowed so sad in kholofrakhs, I axsomclemp mobe her then she svimes.\n",
      "2019-02-08 22:34:09 DEBUG    [('bad_keep', 34), ('bad_pass', 933), ('good', 33)]\n",
      "5960it [00:06, 932.75it/s]2019-02-08 22:34:10 DEBUG    13.059, xpgdekyhijmlbnocqrstavwfuz, This is the storg ox u cirl. Who pried u river und drowned the whole world. And while she loofed so sud in bhotocrubhs, I umsolytelg love her when she skiles.\n",
      "2019-02-08 22:34:10 DEBUG    [('bad_keep', 20), ('bad_pass', 966), ('good', 14)]\n",
      "6962it [00:07, 938.45it/s]2019-02-08 22:34:11 DEBUG    11.263, abpdeughiqylmnocxrstjvwfkz, This is the stork ox a girl. Who pried a river and drowned the whole world. And while she looyed so sad in chotograchs, I absolftelk love her when she smiles.\n",
      "2019-02-08 22:34:11 DEBUG    [('bad_keep', 6), ('bad_pass', 988), ('good', 6)]\n",
      "7978it [00:08, 944.27it/s]2019-02-08 22:34:12 DEBUG    11.192, abpdefghiqklmnocjrstuvwxyz, This is the story of a girl. Who pried a river and drowned the whole world. And while she looked so sad in chotograchs, I absolutely love her when she smiles.\n",
      "2019-02-08 22:34:12 DEBUG    [('bad_keep', 17), ('bad_pass', 973), ('good', 10)]\n",
      "8967it [00:09, 941.83it/s]2019-02-08 22:34:13 DEBUG    10.592, abpdefghizklmnocqrstuvwjyx, This is the story of a girl. Who pried a river and drowned the whole world. And while she looked so sad in chotograchs, I absolutely love her when she smiles.\n",
      "2019-02-08 22:34:13 DEBUG    [('bad_keep', 13), ('bad_pass', 987)]\n",
      "9935it [00:10, 943.27it/s]2019-02-08 22:34:14 DEBUG    10.625, abpdefghizklmnocqrstuvwjyx, This is the story of a girl. Who pried a river and drowned the whole world. And while she looked so sad in chotograchs, I absolutely love her when she smiles.\n",
      "2019-02-08 22:34:14 DEBUG    [('bad_keep', 16), ('bad_pass', 984)]\n",
      "10000it [00:10, 943.02it/s]\n",
      "2019-02-08 22:34:14 INFO     \n",
      "final best (10000 epochs): 10.109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This is the story of a girl. Who pried a river and drowned the whole world. And while she looked so sad in chotograchs, I absolutely love her when she smiles.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'This is the story of a girl. Who cried a river and drowned the whole world. And while she looked so sad in photographs, I absolutely love her when she smiles.'\n",
    "sim_annealer.solve(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ifzn zn ifh nivtm vb c lztq. yfv jtzhk c tzxht cpk ktvyphk ifh yfvqh yvtqk. cpk yfzqh nfh qvvohk nv nck zp afvivltcafn, z cwnvqsihqm qvxh fht yfhp nfh ngzqhn.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = doc.text\n",
    "# text = 'Rbo rpktigo vcrb bwucja wj kloj hcjd, km sktpqo, cq rbwr loklgo vcgg cjqcqr kj skhcja wgkja wjd rpycja rk ltr rbcjaq cj cr. -- Roppy Lpwrsborr'\n",
    "text = 'This is the story of a girl. Who cried a river and drowned the whole world. And while she looked so sad in photographs, I absolutely love her when she smiles.'\n",
    "# text = 'Jail zesty vixen who grabbed pay from quack.'\n",
    "# text = \"I've found that when everyone rallies behind a cause, and when they learn their effort can contribute something bigger, they get engaged.\"\n",
    "# text = str(random.choice(list(nlp(random.choice(articles)).sents)))\n",
    "doc = solver.Doc(text.lower())\n",
    "mapping = solver.Mapping()\n",
    "mapping.scramble()\n",
    "doc = mapping.translate(doc)\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 20:53:57 DEBUG    hi\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "logger.debug('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cryptogram_solver.solver' has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3637716353a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# logging.basicConfig(level=logging.DEBUG)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulated_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-d754fde83b0d>\u001b[0m in \u001b[0;36msimulated_annealing\u001b[0;34m(text, _, tokenizer, num_epochs, is_debug)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbest_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cryptogram_solver.solver' has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "text = simulated_annealing(doc.text, _, tokenizer, 7000)\n",
    "t1 = time()\n",
    "print(text)\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
