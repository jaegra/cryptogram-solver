{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'crypto' from '/Users/chris/Documents/cryptogram-solver/src/crypto.py'>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from string import ascii_lowercase as LETTERS\n",
    "from random import sample, choice, uniform\n",
    "from time import time\n",
    "from math import log, exp\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parents[0] / 'src')) \n",
    "import crypto as cg; reload(cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=20180827)\n",
    "news_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=20180827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Token(ngrams=('this',), kind=<NgramKind: word>, n=1): 1,\n",
       "             Token(ngrams=('is',), kind=<NgramKind: word>, n=1): 1,\n",
       "             Token(ngrams=('a',), kind=<NgramKind: word>, n=1): 1,\n",
       "             Token(ngrams=('sentence',), kind=<NgramKind: word>, n=1): 1,\n",
       "             Token(ngrams=('<',), kind=<NgramKind: char>, n=1): 4,\n",
       "             Token(ngrams=('t',), kind=<NgramKind: char>, n=1): 2,\n",
       "             Token(ngrams=('h',), kind=<NgramKind: char>, n=1): 1,\n",
       "             Token(ngrams=('i',), kind=<NgramKind: char>, n=1): 2,\n",
       "             Token(ngrams=('s',), kind=<NgramKind: char>, n=1): 3,\n",
       "             Token(ngrams=('>',), kind=<NgramKind: char>, n=1): 4,\n",
       "             Token(ngrams=('<', 't'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('t', 'h'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('h', 'i'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('i', 's'), kind=<NgramKind: char>, n=2): 2,\n",
       "             Token(ngrams=('s', '>'), kind=<NgramKind: char>, n=2): 2,\n",
       "             Token(ngrams=('<', 't', 'h'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('t', 'h', 'i'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('h', 'i', 's'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('i', 's', '>'), kind=<NgramKind: char>, n=3): 2,\n",
       "             Token(ngrams=('<', 'i'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('<', 'i', 's'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('a',), kind=<NgramKind: char>, n=1): 1,\n",
       "             Token(ngrams=('<', 'a'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('a', '>'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('<', 'a', '>'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('e',), kind=<NgramKind: char>, n=1): 3,\n",
       "             Token(ngrams=('n',), kind=<NgramKind: char>, n=1): 2,\n",
       "             Token(ngrams=('c',), kind=<NgramKind: char>, n=1): 1,\n",
       "             Token(ngrams=('<', 's'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('s', 'e'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('e', 'n'), kind=<NgramKind: char>, n=2): 2,\n",
       "             Token(ngrams=('n', 't'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('t', 'e'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('n', 'c'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('c', 'e'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('e', '>'), kind=<NgramKind: char>, n=2): 1,\n",
       "             Token(ngrams=('<', 's', 'e'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('s', 'e', 'n'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('e', 'n', 't'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('n', 't', 'e'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('t', 'e', 'n'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('e', 'n', 'c'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('n', 'c', 'e'), kind=<NgramKind: char>, n=3): 1,\n",
       "             Token(ngrams=('c', 'e', '>'), kind=<NgramKind: char>, n=3): 1})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_test = cg.Tokenizer()\n",
    "tokenizer_test.tokenize(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:54<00:00, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73829\n",
      "defaultdict(<class 'int'>, {(<NgramKind: word>, 1): 1586776, (<NgramKind: char>, 1): 9938770, (<NgramKind: char>, 2): 8351994, (<NgramKind: char>, 3): 6765218})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reload(cg)\n",
    "tokenizer = cg.Tokenizer(char_ngram_range=(1, 3), word_ngram_range=(1, 1), vocab_size=1000000)\n",
    "tokenizer.fit(news_train['data'][:5000])\n",
    "print(len(tokenizer.vocab))\n",
    "print(tokenizer.totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(<NgramKind: word>, 1): 1586776,\n",
       "             (<NgramKind: char>, 1): 9938770,\n",
       "             (<NgramKind: char>, 2): 8351994,\n",
       "             (<NgramKind: char>, 3): 6765218})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ftni: pttnibzz@hjslzmdjns.ul.hos.zbs (Kzm Attnibzz)\\nSskhzuq: Rz: Il wq xnnb qopq Jzlsl bwzb?\\nOtxpmwfpqwnm: Jnoml Hnadwml Umweztlwqj CS Dzaq.\\nLwmzl: 31\\n\\nIm ptqwucz <1993Aat26.215627.24917@ntxpmawaz.ssx.ptwfnmp.zbs> ktwpm@cac.ptwfnmp.zbs (Btwpm Czuuptzccw 602/621-9615) gtwqzl:\\n>A kpkj\\'l wmmnuzmuz opl mnqowmx qn bn gwqo gozqozt qoz kpkj\\n>wl p lwmmzt.  Immnuzmuz pmb qoz lwm mpqstz ptz qgn bwvvztzmq pqqtwksqzl. \\n>Toz kpkj wl wmmnuzmq, jzq qoz kpkj wl p lwmmzt.   \\n>Yns opez qgn ptil pmb qgn czxl?  Woj?  Bzupslz jnst aptzmql bwb.\\n>Woj? Bzupslz qozwt aptzmql bwb.  Equ.  Dwb jns bn pmjqowmx qn xzq qozi?\\n\\nToz qowmx wl, I dmng gopq ptil pmb czxl ptz.  Iq\\'l qoztzvntz xzmztpccj zplj qn\\nqzcc gozqozt nt mnq lniznmz opl ptil pmb czxl.  Towl \"lwmvsc mpqstz\", lwmuz wq\\nbnzl mnq tzyswtz qopq qoz kpkj puqspccj aztvnti pmj lwml, lzzil qn kz qnqpccj\\nwmewlwkcz.  Al vpt pl I dmng, ipjkz opcv qoz kpkwzl opez p lwmvsc mpqstz pmb\\nopcv bnm\\'q--wq\\'b cnnd zrpuqcj qoz lpiz, lwmuz qoztz wl mn gpj qn qzcc qoz\\nbwvvztzmuz.\\n\\n>Wz ptz kntm lwmmztl.  Wz ptz kntm lwmmztl kzupslz nst aptzmql\\n>gztz kntm gwqo wq.  Wz xnq wq vtni qozi.  Wz bwb mnqowmx qn zptm\\n>qoz qwqcz \"lwmmzt\".  Wz xzq wq kzupslz nst aptzmql opb wq, qozwt\\n>aptzmql opb wq, qozwt xtpmbaptzmql opb wq, zqu, wmvwmwqsi.\\n\\nSn gopq\\'l ln kpb pknsq p lwmvsc mpqstz, qozm?  I unscb smbztlqpmb wq kzwmx\\nkpb wv wq pcgpjl tzlscql wm aznacz uniiwqqwmx lwml, ksq kpkwzl upm opez wq,\\nmzezt uniiwq lwml, bwz, pmb qozj lqwcc opez wq.  Sn qoz kpb aptq pknsq upm\\'q\\niztzcj kz qopq wq tzlscql wm aznacz uniiwqqwmx lwml--ln gopq _wl_ kpb pknsq wq?\\n--\\n\"Om qoz vwtlq bpj pvqzt Cotwlqipl ij qtszcnez lztezb qn iz...  Lzvqnezt Tstdzj!\\nOm qoz lzunmb bpj pvqzt Cotwlqipl ij qtszcnez lztezb qn iz...  Tstdzj Cpllztncz\\n    qopq loz ipbz vtni Lzvqnezt Tstdzj.\\n[bpjl 3-4 bzczqzb] ...  Fcpiwmx Tstdzj Wwmxl! ...\\n   -- Pwffp Hsq uniiztuwpc (pmb M*qcs/A*xwu kpwq)\\n\\nKzm Attnibzz (pttnibzz@hjslzmdjns.ul.hos.zbs)\\n'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = cg.Doc(news_test['data'][0])\n",
    "mapper = cg.Mapping()\n",
    "mapper.scramble()\n",
    "doc = mapper.translate(doc)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.71828183e+00,   4.72366553e-01,   8.20849986e-02,\n",
       "         1.42642339e-02,   2.47875218e-03])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.linspace(1, -6, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.20264658e+04,   2.38696456e+03,   2.58670631e+02,\n",
       "         2.80316249e+01,   3.03773178e+00,   3.29192988e-01,\n",
       "         3.56739933e-02,   3.86592014e-03,   4.18942123e-04,\n",
       "         4.53999298e-05])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.linspace(10, -10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ideas:\n",
    "> Implement simulated annealing properly (single swap and decision), with a reasonable temp scheduler.\n",
    "  - This works! But need to play with temperature scheduler since results are sensitive to even small changes.\n",
    "> Implement simulated annealing but using softmax and subsetting swap options.\n",
    "> More swaps in the beginning, fewer later.\n",
    "'''\n",
    "\n",
    "solver = cg.Solver(tokenizer, None, 0.1)\n",
    "\n",
    "def simulated_annealing(text, solver, tokenizer, max_epochs=10000, is_debug=True):\n",
    "    best_mapping = mapping = cg.Mapping()\n",
    "    doc = cg.Doc(text)\n",
    "    best_score = solver.score(doc)\n",
    "    epoch = 0\n",
    "    decisions = defaultdict(int)\n",
    "    temps = np.exp(np.linspace(0, -6, 10000))\n",
    "    for temp in tqdm(temps):\n",
    "        # print('*', end='')\n",
    "        improving = False\n",
    "        new_mapping = mapping.random_swap(doc.letters)\n",
    "        new_doc = new_mapping.translate(doc)\n",
    "        score = solver.score(new_doc)\n",
    "        score_change = score - best_score\n",
    "        # if score_change < 0 or exp(-score_change / temp) > uniform(0, 1):\n",
    "        #     print(f'score change: {score_change}')\n",
    "        #     print('updating')\n",
    "        #     best_mapping = mapping\n",
    "        #     best_score = score\n",
    "        if score_change < 0:\n",
    "            # print('updating (improvement)')\n",
    "            best_mapping = new_mapping\n",
    "            best_score = score\n",
    "            decisions['good'] += 1\n",
    "        elif exp(-score_change / temp) > uniform(0, 1):\n",
    "            # Break this out as different section just for debugging.\n",
    "            # print(f'updating (bad change): {score_change}')\n",
    "            best_mapping = new_mapping\n",
    "            best_score = score\n",
    "            decisions['bad_keep'] += 1\n",
    "        else:\n",
    "            decisions['bad_pass'] += 1\n",
    "            # print(f'keeping: {score_change}')\n",
    "        mapping = best_mapping\n",
    "        epoch += 1\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'{score:0.5g}, {mapping.mapping}, {mapping.translate(doc).text}')\n",
    "            print(sorted(list(decisions.items())))\n",
    "            decisions = defaultdict(int)\n",
    "    print(f'\\nfinal best ({epoch} epochs): {best_score:0.5g}')\n",
    "    return mapping.translate(doc).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dlst st dlh tdjak jy w zsao. flj iashc w asuha wvc cajfvhc dlh fljoh fjaoc. wvc flsoh tlh ojjqhc tj twc sv eljdjzawelt, s wgtjomdhok ojuh lha flhv tlh trsoht.'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = doc.text\n",
    "# text = 'Rbo rpktigo vcrb bwucja wj kloj hcjd, km sktpqo, cq rbwr loklgo vcgg cjqcqr kj skhcja wgkja wjd rpycja rk ltr rbcjaq cj cr. -- Roppy Lpwrsborr'\n",
    "text = 'This is the story of a girl. Who cried a river and drowned the whole world. And while she looked so sad in photographs, I absolutely love her when she smiles.'\n",
    "# text = \"I've found that when everyone rallies behind a cause, and when they learn their effort can contribute something bigger, they get engaged.\"\n",
    "doc = cg.Doc(text.lower())\n",
    "mapping = cg.Mapping()\n",
    "mapping.scramble()\n",
    "doc = mapping.translate(doc)\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1086/10000 [00:01<00:13, 667.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.447, ugrhwoklfdnbyceszqtpjavimx, jhps ps jhd sjuvg um e qpvf. ihu xvpdn e vpadv ewn nvuiwdn jhd ihufd iuvfn. ewn ihpfd shd fuurdn su sen pw ohujuqveohs, p ebsufyjdfg fuad hdv ihdw shd scpfds.\n",
      "[('bad_keep', 450), ('bad_pass', 135), ('good', 415)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2097/10000 [00:03<00:12, 649.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.19, hoqylxgcventmpbwrdjaufkisz, reyl yl rea lrstw sd p zytb. ves xtyah p tyuat pih htsviah rea vesba vstbh. pih veyba lea bsscah ls lph yi jesrsztpjel, y pglsbmrabw bsua eat veai lea lqybal.\n",
      "[('bad_keep', 363), ('bad_pass', 227), ('good', 410)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3079/10000 [00:04<00:10, 661.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.517, simbfxrvouktecldzjhwgpnqay, poal al pos lpryk rz t qayi. eor byasn t yajsy thn nyrehsn pos eoris eryin. thn eoais los irrxsn lr ltn ah morprqytmol, a tulricpsik irjs osy eosh los lgaisl.\n",
      "[('bad_keep', 311), ('bad_pass', 381), ('good', 308)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4131/10000 [00:06<00:08, 665.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.691, juachyelqpgobwsrxvtkmdfzin, vhos os vhe svact af n xocl. wha ycoed n cobec nrd dcawred vhe whale wacld. nrd whole she laaied sa snd or ghavaxcnghs, o nksaluvelt labe hec wher she spoles.\n",
      "[('bad_keep', 237), ('bad_pass', 539), ('good', 224)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5107/10000 [00:07<00:07, 667.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.731, jzechyblspqaougknvtdxifrwm, this is the stalp af y bilm. wha vlied y linel yrd dlawred the whame walmd. yrd whime she maaked sa syd ir chatablychs, i yosamztemp mane hel wher she sximes.\n",
      "[('bad_keep', 89), ('bad_pass', 827), ('good', 84)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6084/10000 [00:09<00:05, 668.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.654, wgechzulsxnoqvjrbatdmpfyki, this is the story ox a firl. who zried a riger and drowned the whole world. and while she loomed so sad in chotofrachs, i absolutely loge her when she spiles.\n",
      "[('bad_keep', 39), ('bad_pass', 909), ('good', 52)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 7139/10000 [00:10<00:04, 670.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.094, wgechyzlspqonvjrbatdmufxki, this is the story of a girl. who zried a river and drowned the whole world. and while she looked so sad in chotograchs, i absolutely love her when she spiles.\n",
      "[('bad_keep', 8), ('bad_pass', 977), ('good', 15)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8096/10000 [00:12<00:02, 670.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.167, wgechizlspqorvjybatdmufxkn, this is the story op a girl. who fried a river and drowned the whole world. and while she looked so sad in chotograchs, i absolutely love her when she smiles.\n",
      "[('bad_keep', 2), ('bad_pass', 995), ('good', 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9096/10000 [00:13<00:01, 672.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.748, wgechyzlspqorvjibatdmufxkn, this is the story of a girl. who pried a river and drowned the whole world. and while she looked so sad in chotograchs, i absolutely love her when she smiles.\n",
      "[('bad_keep', 1), ('bad_pass', 997), ('good', 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:14<00:00, 671.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.454, wgichyzlspqorvjebatdmufxkn, this is the story of a girl. who cried a river and drowned the whole world. and while she looked so sad in photographs, i absolutely love her when she smiles.\n",
      "[('bad_keep', 2), ('bad_pass', 997), ('good', 1)]\n",
      "\n",
      "final best (10000 epochs): 10.3\n",
      "this is the story of a girl. who cried a river and drowned the whole world. and while she looked so sad in photographs, i absolutely love her when she smiles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timer = cg.Timer()\n",
    "timer.tic()\n",
    "text = simulated_annealing(doc.text, solver, tokenizer)\n",
    "timer.toc()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
